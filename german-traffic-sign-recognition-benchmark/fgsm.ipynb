{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0fe960-e9be-4f5f-8afc-de69485bb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538ab1f3-0845-4718-9717-9e34c0932112",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "pretrained_model = \"classification.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba41e04a-b2f1-465b-a4b4-f9c762240657",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"data/Train\"\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize([112, 112]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_data = datasets.ImageFolder(root = test_data_path, transform = data_transforms)\n",
    "test_loader = data.DataLoader(test_data, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027ba88b-ac8d-4dd2-8510-6b95b49ef98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256*7*7, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=1000, out_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8660086b-968f-4b56-8c83-57834f533ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f353bf00-ae31-49e1-8abb-c7781623ebf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=12544, out_features=1000, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=256, out_features=43, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(43).to(device)\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b24dc6d5-2818-412b-8a1d-ada6cd3b36d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    \n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e427efe8-fc5a-486a-9030-63f76d08dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, epsilon):\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data.requires_grad = True\n",
    "        \n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "        \n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "            \n",
    "        loss = F.nll_loss(output, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        data_grad = data.grad.data\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "        output = model(perturbed_data)\n",
    "        \n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        \n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ca9f9-9698-44b1-bc6b-b7a1283bc539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaolong/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\tTest Accuracy = 39177 / 39209 = 0.9991838608482746\n",
      "Epsilon: 0.05\tTest Accuracy = 4642 / 39209 = 0.11839118569716137\n",
      "Epsilon: 0.1\tTest Accuracy = 1158 / 39209 = 0.029534035553061798\n",
      "Epsilon: 0.15\tTest Accuracy = 438 / 39209 = 0.01117090463924099\n",
      "Epsilon: 0.2\tTest Accuracy = 213 / 39209 = 0.005432426228671988\n",
      "Epsilon: 0.25\tTest Accuracy = 127 / 39209 = 0.003239052258410059\n"
     ]
    }
   ],
   "source": [
    "# test(model, device, test_loader, 0.3)\n",
    "accuracies = []\n",
    "examples = []\n",
    "# epsilons = [0.05]\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be2f58-a462-4f2b-b6ea-ca3a3e994c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9bda1-1be7-42c6-ab8e-1107fac2299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3e462-5b11-4a48-9ca9-dfe3d2ef7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        plt.title(\"{} -> {}\".format(orig, adv))\n",
    "#         plt.imshow(ex, cmap=\"gray\")\n",
    "        ex = np.reshape(ex, (112, 112, 3))\n",
    "        print(ex.shape)\n",
    "        plt.imshow(ex)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04bbaf-34ed-492a-b91d-fe72d47d4b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
